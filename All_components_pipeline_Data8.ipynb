{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All components_pipeline_Data8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzSygNcXMel36rVExTzunf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olya-ibragimova/hello-github/blob/master/All_components_pipeline_Data8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0vSd_6qdJ5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63ebeb3e-30a9-40cb-ff8f-9faa8206af11"
      },
      "source": [
        "%%time\n",
        "# Uses python3\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "from datetime import datetime\n",
        "import os\n",
        "import scipy\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau, LearningRateScheduler, Callback, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "from keras import backend as K\n",
        "from keras.utils import multi_gpu_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "plt.rcParams.update({'font.size': 22})\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "range_curves = 250\n",
        "num_of_points = 250\n",
        "out = \"s22\"\n",
        "patience = 400\n",
        "a = 6\n",
        "\n",
        "# Loading data\n",
        "print(\"Loading data\")\n",
        "data = np.asarray(h5py.File('/content/drive/My Drive/Datasets/Data8/data8_train.h5', 'r')['data'])\n",
        "print(data.shape)\n",
        "data_test = np.asarray(h5py.File('/content/drive/My Drive/Datasets/Data8/data8_test.h5', 'r')['data'])\n",
        "print(data_test.shape)\n",
        "\n",
        "# Loading normalization parameters\n",
        "data_max = np.loadtxt('/content/drive/My Drive/Datasets/Data8/data8_max.csv', delimiter=',')\n",
        "data_min = np.loadtxt('/content/drive/My Drive/Datasets/Data8/data8_min.csv', delimiter=',')\n",
        "\n",
        "# Some helper variables:\n",
        "max_y_lim = [350,\n",
        "            1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "            950, 900, 900, 750, 550, 550,\n",
        "            0.25]\n",
        "min_y_lim = [0,\n",
        "            -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "            -950, -900, -900, -750, -550, -550,\n",
        "            0]\n",
        "units = [\" MPa\",\n",
        "        \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\n",
        "        \" MPa\", \" MPa\", \" MPa\", \" MPa\", \" MPa\", \" MPa\",\n",
        "        \"\"]\n",
        "\n",
        "from_ = []\n",
        "to_ = []\n",
        "\n",
        "out_ = ['g',\n",
        "    'r1',  'r2',  'r3',  'r4',  'r5',  'r6',  'r7',  'r8',  'r9',\n",
        "    's11', 's22', 's33', 's12', 's13', 's23',\n",
        "    'ashear']\n",
        "\n",
        "c = 0\n",
        "for i in out_:\n",
        "    from_.append(15+c*num_of_points)\n",
        "    to_.append(15+(c+1)*num_of_points)\n",
        "    c+=1\n",
        "    \n",
        "print(from_)\n",
        "print(to_)\n",
        "\n",
        "activation = 'tanh'\n",
        "metrics = ['mse', 'mape']\n",
        "optimizer = 'adam'\n",
        "loss = 'mean_squared_error'\n",
        "kernel_init =  'glorot_uniform'\n",
        "\n",
        "# for out in  ['g',\n",
        "#       'r1',  'r2',  'r3',  'r4',  'r5',  'r6',  'r7',  'r8',  'r9',\n",
        "#       's11', 's22', 's33', 's12', 's13', 's23',\n",
        "#       'ashear']:  \n",
        "\n",
        "index_ = out_.index(out)\n",
        "\n",
        "cols = ['tau0','h0',\n",
        "    'd11', 'd22', 'd33', 'd12',\n",
        "    'r1_init','r2_init', 'r3_init', 'r4_init', \n",
        "    'r5_init', 'r6_init', 'r7_init', 'r8_init', 'r9_init']\n",
        "\n",
        "print(\"input:\t\",cols[:cols.index('r9_init') + 1])\n",
        "print(\"output:\t {} curve ({} values)\".format(out, -from_[index_]+to_[index_]))\n",
        "print(out, index_, from_[index_], to_[index_])\n",
        "\n",
        "# X & Y test\n",
        "X_test = data_test[:,:cols.index('r9_init') + 1]\n",
        "y_test = data_test[:,from_[index_]:to_[index_]][:,::a]\n",
        "\n",
        "\n",
        "# samples_in_training_data = 120000\n",
        "permutation = list(np.random.permutation(data.shape[0]))\n",
        "data_temp = data[permutation,:]\n",
        "# data_temp = data_temp[:int(samples_in_training_data),:]\n",
        "\n",
        "# X & Y train\n",
        "X_train = data_temp[:,:cols.index('r9_init') + 1]\n",
        "y_train = data_temp[:,from_[index_]:to_[index_]][:,::a]\n",
        "# Setting up some hyperparameters:\n",
        "\n",
        "\n",
        "# Model:\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_dim=X_train.shape[1], kernel_initializer=kernel_init, activation=activation))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1024, kernel_initializer = kernel_init, activation = activation))\n",
        "model.add(Dense(1024, kernel_initializer = kernel_init, activation = activation))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, kernel_initializer = kernel_init, activation = activation))\n",
        "model.add(Dense(512, kernel_initializer = kernel_init, activation = activation))\n",
        "model.add(Dense(512, kernel_initializer = kernel_init, activation = activation))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, kernel_initializer = kernel_init, activation = activation))\n",
        "model.add(Dense(256, kernel_initializer = kernel_init, activation = activation))\n",
        "model.add(Dense(256, kernel_initializer = kernel_init, activation = activation))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(y_train.shape[1], kernel_initializer='normal'))\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "name_ckpt = 'checkpoint_data8_0706_{}.h5'.format(out)\n",
        "\n",
        "checkpoint = ModelCheckpoint(name_ckpt, \n",
        "                            monitor='val_mse', \n",
        "                            verbose=1, save_best_only=True, mode='min')\n",
        "batch_size = 2**13\n",
        "\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "hist = model.fit(\n",
        "    X_train, y_train, \n",
        "    epochs=patience, \n",
        "    batch_size=batch_size, \n",
        "    callbacks=callbacks_list, \n",
        "    validation_split=0.15, \n",
        "    shuffle=True, verbose = 2)\n",
        "\n",
        "model = load_model(name_ckpt)\n",
        "print('Best val_score model is loaded'.format(out))\n",
        "preds = model.predict(X_test, batch_size=8196)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(\"test mse:\t\",mean_squared_error(y_test, preds))\n",
        "\n",
        "data_max_x = data_max[:cols.index('r9_init') + 1]\n",
        "data_min_x = data_min[:cols.index('r9_init') + 1]\n",
        "    \n",
        "data_max_y = data_max[from_[index_]:to_[index_]][::a]\n",
        "data_min_y = data_min[from_[index_]:to_[index_]][::a]\n",
        "\n",
        "y_test = (y_test + 1)*(data_max_y - data_min_y)/2 + data_min_y\n",
        "preds =  (preds  + 1)*(data_max_y - data_min_y)/2 + data_min_y\n",
        "X_test = (X_test + 1)*(data_max_x - data_min_x)/2 + data_min_x\n",
        "\n",
        "print(\"test MSE:\t\",mean_squared_error(y_test, preds))\n",
        "print(\"test RMSE:\t\",np.sqrt(mean_squared_error(y_test, preds)))\n",
        "\n",
        "figs_ = '/content/drive/My Drive/Figures/Data8/figs_data8_{}_4'.format(out)\n",
        "\n",
        "if not os.path.isdir(figs_):\n",
        "    os.mkdir(figs_)\n",
        "    print(figs_ + \" has come into existence\".format(out))\n",
        "\n",
        "plt.figure()\n",
        "fig, _ = plt.subplots(figsize=(15, 9))\n",
        "plt.semilogy(hist.history['mse'],linewidth=4, label = 'On training set')\n",
        "plt.semilogy(hist.history['val_mse'],linewidth=4, label = 'On validation set', alpha = 0.8)\n",
        "plt.semilogy(savgol_filter(hist.history['val_mse'], 51, 3),linewidth=4, label = 'On validation set', alpha = 0.8)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('Model')\n",
        "plt.xlim(0,patience+5)\n",
        "plt.grid(which = 'both', linestyle = ':')\n",
        "plt.legend()\n",
        "plt.savefig(figs_+'/mse_{0}.png'.format(out))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "fig, _ = plt.subplots(figsize=(15, 9))\n",
        "plt.semilogy(hist.history['mape'], label = 'On training set')\n",
        "plt.semilogy(hist.history['val_mape'], label = 'On validation set', alpha = 0.8)\n",
        "plt.semilogy(savgol_filter(hist.history['val_mape'], 51, 3), label = 'On validation set (smooth)', alpha = 0.8)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAPE')\n",
        "plt.title('Model')\n",
        "plt.xlim(0,patience+5)\n",
        "plt.grid(which = 'both', linestyle = ':')\n",
        "plt.legend()\n",
        "plt.savefig(figs_+'/mape_{0}.png'.format(out))\n",
        "plt.show()\n",
        "\n",
        "print(\"Plotting curves... \")\n",
        "for curves in range(range_curves):\n",
        "    # print(X_test[curves, :])\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.plot(y_test[curves,:], \"o-\", linewidth=4, label = \"CP Simulation\")\n",
        "    plt.plot(preds[curves,:], \"s-\", linewidth=4, alpha = 0.8, label = \"ML Prediction\")\n",
        "    plt.plot([], linewidth=0, label=\"RMSE = {0:1.2f} {1}\".format(\n",
        "        np.sqrt(mean_squared_error(y_test[curves,:],preds[curves,:])),\n",
        "                units[out_.index(out)]))\n",
        "    plt.grid(color='gray', linestyle=':', linewidth=0.5)\n",
        "    plt.title(\"Test set, ML prediction: {}\".format(out))\n",
        "    plt.ylim((min_y_lim[out_.index(out)], max_y_lim[out_.index(out)]))\n",
        "    plt.legend()\n",
        "    plt.savefig(figs_+'/res_{0}_{1}.png'.format(out,curves))\n",
        "    # print('/res_{0}_{1}.png'.format(out,curves))\n",
        "    plt.close()\n",
        "\n",
        "print(\"Complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Loading data\n",
            "(154888, 4265)\n",
            "(17209, 4265)\n",
            "[15, 265, 515, 765, 1015, 1265, 1515, 1765, 2015, 2265, 2515, 2765, 3015, 3265, 3515, 3765, 4015]\n",
            "[265, 515, 765, 1015, 1265, 1515, 1765, 2015, 2265, 2515, 2765, 3015, 3265, 3515, 3765, 4015, 4265]\n",
            "input:\t ['tau0', 'h0', 'd11', 'd22', 'd33', 'd12', 'r1_init', 'r2_init', 'r3_init', 'r4_init', 'r5_init', 'r6_init', 'r7_init', 'r8_init', 'r9_init']\n",
            "output:\t s22 curve (250 values)\n",
            "s22 11 2765 3015\n",
            "Train on 131654 samples, validate on 23234 samples\n",
            "Epoch 1/400\n",
            " - 4s - loss: 0.0901 - mse: 0.0901 - mape: 4238.8442 - val_loss: 0.0337 - val_mse: 0.0337 - val_mape: 3429.9592\n",
            "\n",
            "Epoch 00001: val_mse improved from inf to 0.03366, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 2/400\n",
            " - 2s - loss: 0.0458 - mse: 0.0458 - mape: 3471.0815 - val_loss: 0.0316 - val_mse: 0.0316 - val_mape: 2904.2473\n",
            "\n",
            "Epoch 00002: val_mse improved from 0.03366 to 0.03157, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 3/400\n",
            " - 2s - loss: 0.0397 - mse: 0.0397 - mape: 3378.0708 - val_loss: 0.0303 - val_mse: 0.0303 - val_mape: 3344.3115\n",
            "\n",
            "Epoch 00003: val_mse improved from 0.03157 to 0.03027, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 4/400\n",
            " - 2s - loss: 0.0363 - mse: 0.0363 - mape: 3067.6179 - val_loss: 0.0292 - val_mse: 0.0292 - val_mape: 3261.1238\n",
            "\n",
            "Epoch 00004: val_mse improved from 0.03027 to 0.02917, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 5/400\n",
            " - 2s - loss: 0.0344 - mse: 0.0344 - mape: 2898.2581 - val_loss: 0.0276 - val_mse: 0.0276 - val_mape: 2858.8335\n",
            "\n",
            "Epoch 00005: val_mse improved from 0.02917 to 0.02760, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 6/400\n",
            " - 2s - loss: 0.0322 - mse: 0.0322 - mape: 2709.1096 - val_loss: 0.0235 - val_mse: 0.0235 - val_mape: 2215.2390\n",
            "\n",
            "Epoch 00006: val_mse improved from 0.02760 to 0.02350, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 7/400\n",
            " - 2s - loss: 0.0331 - mse: 0.0331 - mape: 2819.0967 - val_loss: 0.0276 - val_mse: 0.0276 - val_mape: 3568.2053\n",
            "\n",
            "Epoch 00007: val_mse did not improve from 0.02350\n",
            "Epoch 8/400\n",
            " - 2s - loss: 0.0287 - mse: 0.0287 - mape: 2718.1394 - val_loss: 0.0186 - val_mse: 0.0186 - val_mape: 2335.1787\n",
            "\n",
            "Epoch 00008: val_mse improved from 0.02350 to 0.01864, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 9/400\n",
            " - 2s - loss: 0.0239 - mse: 0.0239 - mape: 2433.8657 - val_loss: 0.0186 - val_mse: 0.0186 - val_mape: 2093.2886\n",
            "\n",
            "Epoch 00009: val_mse improved from 0.01864 to 0.01856, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 10/400\n",
            " - 2s - loss: 0.0223 - mse: 0.0223 - mape: 2476.3247 - val_loss: 0.0156 - val_mse: 0.0156 - val_mape: 2082.2112\n",
            "\n",
            "Epoch 00010: val_mse improved from 0.01856 to 0.01556, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 11/400\n",
            " - 2s - loss: 0.0204 - mse: 0.0204 - mape: 2349.6294 - val_loss: 0.0143 - val_mse: 0.0143 - val_mape: 1991.5812\n",
            "\n",
            "Epoch 00011: val_mse improved from 0.01556 to 0.01430, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 12/400\n",
            " - 2s - loss: 0.0193 - mse: 0.0193 - mape: 2348.2021 - val_loss: 0.0144 - val_mse: 0.0144 - val_mape: 2479.3086\n",
            "\n",
            "Epoch 00012: val_mse did not improve from 0.01430\n",
            "Epoch 13/400\n",
            " - 2s - loss: 0.0182 - mse: 0.0182 - mape: 2271.0632 - val_loss: 0.0126 - val_mse: 0.0126 - val_mape: 1679.3656\n",
            "\n",
            "Epoch 00013: val_mse improved from 0.01430 to 0.01261, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 14/400\n",
            " - 2s - loss: 0.0176 - mse: 0.0176 - mape: 2141.9580 - val_loss: 0.0122 - val_mse: 0.0122 - val_mape: 1754.8828\n",
            "\n",
            "Epoch 00014: val_mse improved from 0.01261 to 0.01222, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 15/400\n",
            " - 2s - loss: 0.0183 - mse: 0.0183 - mape: 2114.7732 - val_loss: 0.0227 - val_mse: 0.0227 - val_mape: 1699.1295\n",
            "\n",
            "Epoch 00015: val_mse did not improve from 0.01222\n",
            "Epoch 16/400\n",
            " - 2s - loss: 0.0194 - mse: 0.0194 - mape: 2352.2874 - val_loss: 0.0130 - val_mse: 0.0130 - val_mape: 1590.6506\n",
            "\n",
            "Epoch 00016: val_mse did not improve from 0.01222\n",
            "Epoch 17/400\n",
            " - 2s - loss: 0.0153 - mse: 0.0153 - mape: 1907.4368 - val_loss: 0.0100 - val_mse: 0.0100 - val_mape: 1480.7861\n",
            "\n",
            "Epoch 00017: val_mse improved from 0.01222 to 0.01004, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 18/400\n",
            " - 2s - loss: 0.0140 - mse: 0.0140 - mape: 2034.2932 - val_loss: 0.0106 - val_mse: 0.0106 - val_mape: 1350.8865\n",
            "\n",
            "Epoch 00018: val_mse did not improve from 0.01004\n",
            "Epoch 19/400\n",
            " - 2s - loss: 0.0138 - mse: 0.0138 - mape: 1882.5857 - val_loss: 0.0097 - val_mse: 0.0097 - val_mape: 1627.9010\n",
            "\n",
            "Epoch 00019: val_mse improved from 0.01004 to 0.00974, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 20/400\n",
            " - 2s - loss: 0.0135 - mse: 0.0135 - mape: 1873.2307 - val_loss: 0.0099 - val_mse: 0.0099 - val_mape: 1636.9147\n",
            "\n",
            "Epoch 00020: val_mse did not improve from 0.00974\n",
            "Epoch 21/400\n",
            " - 2s - loss: 0.0132 - mse: 0.0132 - mape: 1684.5035 - val_loss: 0.0102 - val_mse: 0.0102 - val_mape: 1570.8950\n",
            "\n",
            "Epoch 00021: val_mse did not improve from 0.00974\n",
            "Epoch 22/400\n",
            " - 2s - loss: 0.0133 - mse: 0.0133 - mape: 1809.3937 - val_loss: 0.0095 - val_mse: 0.0095 - val_mape: 1951.5359\n",
            "\n",
            "Epoch 00022: val_mse improved from 0.00974 to 0.00945, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 23/400\n",
            " - 2s - loss: 0.0123 - mse: 0.0123 - mape: 1772.6265 - val_loss: 0.0082 - val_mse: 0.0082 - val_mape: 1496.2980\n",
            "\n",
            "Epoch 00023: val_mse improved from 0.00945 to 0.00825, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 24/400\n",
            " - 2s - loss: 0.0119 - mse: 0.0119 - mape: 1647.5061 - val_loss: 0.0087 - val_mse: 0.0087 - val_mape: 1508.1663\n",
            "\n",
            "Epoch 00024: val_mse did not improve from 0.00825\n",
            "Epoch 25/400\n",
            " - 2s - loss: 0.0118 - mse: 0.0118 - mape: 1721.7188 - val_loss: 0.0087 - val_mse: 0.0087 - val_mape: 1345.4086\n",
            "\n",
            "Epoch 00025: val_mse did not improve from 0.00825\n",
            "Epoch 26/400\n",
            " - 2s - loss: 0.0115 - mse: 0.0115 - mape: 1666.7841 - val_loss: 0.0080 - val_mse: 0.0080 - val_mape: 1322.3397\n",
            "\n",
            "Epoch 00026: val_mse improved from 0.00825 to 0.00803, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 27/400\n",
            " - 2s - loss: 0.0108 - mse: 0.0108 - mape: 1757.9000 - val_loss: 0.0077 - val_mse: 0.0077 - val_mape: 1362.8234\n",
            "\n",
            "Epoch 00027: val_mse improved from 0.00803 to 0.00772, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 28/400\n",
            " - 2s - loss: 0.0127 - mse: 0.0127 - mape: 1857.6184 - val_loss: 0.0093 - val_mse: 0.0093 - val_mape: 1388.8268\n",
            "\n",
            "Epoch 00028: val_mse did not improve from 0.00772\n",
            "Epoch 29/400\n",
            " - 2s - loss: 0.0113 - mse: 0.0113 - mape: 1840.8557 - val_loss: 0.0085 - val_mse: 0.0085 - val_mape: 962.1865\n",
            "\n",
            "Epoch 00029: val_mse did not improve from 0.00772\n",
            "Epoch 30/400\n",
            " - 2s - loss: 0.0108 - mse: 0.0108 - mape: 1683.3373 - val_loss: 0.0070 - val_mse: 0.0070 - val_mape: 1105.9686\n",
            "\n",
            "Epoch 00030: val_mse improved from 0.00772 to 0.00702, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 31/400\n",
            " - 2s - loss: 0.0101 - mse: 0.0101 - mape: 1507.0496 - val_loss: 0.0075 - val_mse: 0.0075 - val_mape: 1371.7169\n",
            "\n",
            "Epoch 00031: val_mse did not improve from 0.00702\n",
            "Epoch 32/400\n",
            " - 2s - loss: 0.0101 - mse: 0.0101 - mape: 1669.6450 - val_loss: 0.0097 - val_mse: 0.0097 - val_mape: 1722.4733\n",
            "\n",
            "Epoch 00032: val_mse did not improve from 0.00702\n",
            "Epoch 33/400\n",
            " - 2s - loss: 0.0111 - mse: 0.0111 - mape: 1742.2778 - val_loss: 0.0073 - val_mse: 0.0073 - val_mape: 1014.4034\n",
            "\n",
            "Epoch 00033: val_mse did not improve from 0.00702\n",
            "Epoch 34/400\n",
            " - 2s - loss: 0.0097 - mse: 0.0097 - mape: 1560.5330 - val_loss: 0.0072 - val_mse: 0.0072 - val_mape: 1254.3192\n",
            "\n",
            "Epoch 00034: val_mse did not improve from 0.00702\n",
            "Epoch 35/400\n",
            " - 2s - loss: 0.0096 - mse: 0.0096 - mape: 1553.0187 - val_loss: 0.0074 - val_mse: 0.0074 - val_mape: 1296.2308\n",
            "\n",
            "Epoch 00035: val_mse did not improve from 0.00702\n",
            "Epoch 36/400\n",
            " - 2s - loss: 0.0100 - mse: 0.0100 - mape: 1547.9868 - val_loss: 0.0071 - val_mse: 0.0071 - val_mape: 1168.7020\n",
            "\n",
            "Epoch 00036: val_mse did not improve from 0.00702\n",
            "Epoch 37/400\n",
            " - 2s - loss: 0.0095 - mse: 0.0095 - mape: 1625.4917 - val_loss: 0.0072 - val_mse: 0.0072 - val_mape: 1370.9280\n",
            "\n",
            "Epoch 00037: val_mse did not improve from 0.00702\n",
            "Epoch 38/400\n",
            " - 2s - loss: 0.0095 - mse: 0.0095 - mape: 1500.9067 - val_loss: 0.0069 - val_mse: 0.0069 - val_mape: 1333.0819\n",
            "\n",
            "Epoch 00038: val_mse improved from 0.00702 to 0.00688, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 39/400\n",
            " - 2s - loss: 0.0091 - mse: 0.0091 - mape: 1421.2722 - val_loss: 0.0065 - val_mse: 0.0065 - val_mape: 1054.8856\n",
            "\n",
            "Epoch 00039: val_mse improved from 0.00688 to 0.00651, saving model to checkpoint_data8_0706_s22.h5\n",
            "Epoch 40/400\n",
            " - 2s - loss: 0.0089 - mse: 0.0089 - mape: 1490.8588 - val_loss: 0.0081 - val_mse: 0.0081 - val_mape: 1071.1887\n",
            "\n",
            "Epoch 00040: val_mse did not improve from 0.00651\n",
            "Epoch 41/400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAgbHe793ysm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}